{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import math\n",
    "\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f35272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import trimesh\n",
    "import pyrender\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Загрузка файла PLY\n",
    "# input_ply = 'Fashion3D/point_cloud/3/3-1.ply'\n",
    "def ply2obj(class_id, ply_name):\n",
    "    point_cloud = o3d.io.read_point_cloud(f'Fashion3D/point_cloud/{class_id}/{ply_name}')\n",
    "\n",
    "    # Оценка нормалей\n",
    "    point_cloud.estimate_normals()\n",
    "\n",
    "    # Построение меша с использованием Poisson Surface Reconstruction\n",
    "    mesh, _ = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(point_cloud, depth=8, n_threads=1)\n",
    "\n",
    "    # Удаление избыточных частей меша\n",
    "    bbox = o3d.geometry.AxisAlignedBoundingBox(min_bound=(-0.5, -0.5, -0.5), max_bound=(0.5, 0.5, 0.5))\n",
    "    mesh = mesh.crop(bbox)\n",
    "\n",
    "    # Центрирование объекта\n",
    "    mesh.compute_vertex_normals()\n",
    "    mesh_center = mesh.get_center()\n",
    "    translation = -mesh_center\n",
    "    mesh.translate(translation, relative=False)\n",
    "\n",
    "    # Сохранение результата в файл формата OBJ\n",
    "    output_obj = f\"Fashion3D/obj_dataset/{class_id}/{ply_name.replace('ply', 'obj')}\"\n",
    "    os.makedirs(f\"Fashion3D/obj_dataset/{class_id}\", exist_ok=True)\n",
    "    o3d.io.write_triangle_mesh(output_obj, mesh, write_vertex_normals=True)\n",
    "    \n",
    "    return output_obj\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_camera_matrix(rotation_angle, tilt_angle, offset, shift_left=0, shift_right=0, shift_up=0, shift_down=0, roll_angle=0):\n",
    "    \"\"\"\n",
    "    Функция для получения матрицы преобразования координат камеры.\n",
    "    \"\"\"\n",
    "    # Поворачиваем камеру на заданный угол в горизонтальной плоскости.\n",
    "    rotation_matrix = np.array([\n",
    "        [np.cos(rotation_angle), 0, np.sin(rotation_angle), 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [-np.sin(rotation_angle), 0, np.cos(rotation_angle), 0],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "    # Наклоняем камеру на заданный угол в вертикальной плоскости.\n",
    "    tilt_matrix = np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, np.cos(tilt_angle), -np.sin(tilt_angle), 0],\n",
    "        [0, np.sin(tilt_angle), np.cos(tilt_angle), 0],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "    \n",
    "    # Поворачиваем камеру вокруг оси Z на заданный угол.\n",
    "    roll_matrix = np.array([\n",
    "        [np.cos(roll_angle), -np.sin(roll_angle), 0, 0],\n",
    "        [np.sin(roll_angle), np.cos(roll_angle), 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "    # Смещаем камеру назад на заданное расстояние.\n",
    "    offset_matrix = np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 1, offset],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "    # Смещаем камеру влево, вправо, вверх и вниз.\n",
    "    shift_matrix = np.array([\n",
    "        [1, 0, 0, -shift_left + shift_right],\n",
    "        [0, 1, 0, -shift_down + shift_up],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "    # Получаем итоговую матрицу преобразования координат камеры.\n",
    "    camera_matrix = offset_matrix @ tilt_matrix @ roll_matrix @ rotation_matrix @ shift_matrix\n",
    "\n",
    "    return camera_matrix\n",
    "\n",
    "\n",
    "def obj2png_with_aug(obj_file, output_dir, output_ply_dir):\n",
    "    \n",
    "    camera_presets = {\n",
    "        \"Поворот на 45 градусов вправо\": (np.pi / 4, 0, random.uniform(1.23, 1.27), 0, random.uniform(0.74, 0.76), 0.1, 0., 0),\n",
    "        \"Поворот на 45 градусов влево\": (-np.pi / 4, 0, random.uniform(1.23, 1.27), random.uniform(0.79, 0.81), 0, 0.1, 0., 0),\n",
    "        \"Вид спереди под углом\": (0, 0, random.uniform(0.97, 1.03), 0, 0, 0.125, 0, random.uniform(-math.pi/4, math.pi/4)),\n",
    "        \"Вид спереди\": (0, 0, 1, 0, 0, 0.125, 0., 0),\n",
    "        \"Вид снизу на 45 градусов\": (np.pi / 4, np.pi / 4, random.uniform(1.48, 1.52), 0, random.uniform(0.74, 0.76), 0, 0.95, 0),\n",
    "        \"Вид сверху под углом\": (np.pi / 8, -np.pi / 4, random.uniform(1.23, 1.27), 0, 0.25, random.uniform(0.98, 1.02), 0, 0)\n",
    "    }\n",
    "    \n",
    "    width, height = 800, 800\n",
    "    renderer = pyrender.OffscreenRenderer(width, height)  # Создайте экземпляр pyrender.OffscreenRenderer здесь\n",
    "\n",
    "    for preset_name, _ in camera_presets.items():\n",
    "        \n",
    "        rotation_angle, tilt_angle, offset, shift_left, shift_right, shift_up, shift_down, roll_angle = camera_presets[preset_name]\n",
    "        # Получаем матрицу преобразования координат камеры.\n",
    "        camera_matrix = get_camera_matrix(rotation_angle, tilt_angle, offset, shift_left, shift_right, shift_up, shift_down, roll_angle)\n",
    "\n",
    "        mesh = trimesh.load(obj_file)\n",
    "\n",
    "        # Создайте сцену для рендеринга\n",
    "        scene = pyrender.Scene()\n",
    "\n",
    "        # Добавьте меш с вершинными цветами в сцену\n",
    "        material = pyrender.MetallicRoughnessMaterial(\n",
    "            metallicFactor=0.0,\n",
    "            alphaMode='OPAQUE',\n",
    "            baseColorFactor=(1.0, 1.0, 1.0, 1.0),\n",
    "        )\n",
    "        scene.add(pyrender.Mesh.from_trimesh(mesh, material=material))\n",
    "\n",
    "        # Установите камеру\n",
    "        camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "        camera_pose = np.array(camera_matrix)\n",
    "        scene.add(camera, pose=camera_pose)\n",
    "\n",
    "        # Добавьте источник света\n",
    "        light = pyrender.PointLight(color=np.ones(3), intensity=50.0)\n",
    "        light_pose = np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 3],\n",
    "            [0, 0, 1, 3],\n",
    "            [0, 0, 0, 1],\n",
    "        ])\n",
    "        scene.add(light, pose=light_pose)\n",
    "\n",
    "        # Рендеринг сцены\n",
    "        color, depth = renderer.render(scene)\n",
    "\n",
    "        # Сохраните изображение в формате PNG\n",
    "        image = Image.fromarray(color)\n",
    "        image.save(os.path.join(output_dir, f\"{preset_name}.png\"))\n",
    "    \n",
    "    renderer.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252bac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_class_ids(file_name):\n",
    "    class_ids = {}\n",
    "    with open(file_name, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            line_data = line.strip().split()\n",
    "            class_name = line_data[0]\n",
    "            ids = [int(i) for i in line_data[1:]]\n",
    "            class_ids[class_name] = ids\n",
    "    return class_ids\n",
    "\n",
    "def scatter_to_image(x_view, y_view, colors, point_size):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x_view, y_view, c=colors, s=point_size)\n",
    "    ax.axis(\"equal\")\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    fig.canvas.draw()\n",
    "    img_arr = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    img_arr = img_arr.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60edc4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import trimesh\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "file_name = 'Fashion3D/cloth_type_list.txt'\n",
    "class_idss = parse_class_ids(file_name)\n",
    "\n",
    "root_dir = \"Fashion3D\"\n",
    "\n",
    "for class_name, class_ids in class_idss.items():\n",
    "    for class_id in class_ids:\n",
    "        input_dir = os.path.join(root_dir, \"obj_dataset\", str(class_id))\n",
    "        output_dir = os.path.join(root_dir, \"2D_representation_new\", str(class_id))\n",
    "        if os.path.exists(input_dir) and not os.path.exists(output_dir):\n",
    "            for file_name in os.listdir(input_dir):\n",
    "                if file_name.endswith(\".obj\") and 'aug' not in file_name:\n",
    "                    obj_file = f\"Fashion3D/obj_dataset/{class_id}/{file_name.replace('ply', 'obj')}\"\n",
    "                    output_subdir = os.path.join(output_dir, file_name[:-4])\n",
    "                    os.makedirs(output_subdir, exist_ok=True)\n",
    "                    print(obj_file, output_subdir, input_dir)\n",
    "\n",
    "                    obj2png_with_aug(obj_file, output_subdir, input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ac53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "representation_root = \"Fashion3D/2D_representation_new\"\n",
    "point_cloud_root = \"Fashion3D/point_cloud\"\n",
    "\n",
    "\n",
    "data = []\n",
    "for class_id in os.listdir(representation_root):\n",
    "    class_dir = os.path.join(point_cloud_root, str(class_id))\n",
    "    ply_files = glob.glob(os.path.join(class_dir, \"*.ply\"))\n",
    "    \n",
    "    for ply_file in ply_files:\n",
    "        \n",
    "        ply_file_name = os.path.basename(ply_file)\n",
    "\n",
    "        representation_dir = os.path.join(representation_root, str(class_id), ply_file_name[:-4])\n",
    "        jpg_files = glob.glob(os.path.join(representation_dir, \"*.png\"))\n",
    "\n",
    "        for jpg_file in jpg_files:\n",
    "            if ('Вид спереди' in jpg_file and 'Вид спереди под углом' not in jpg_file):\n",
    "                jpg_file_name = os.path.basename(jpg_file)\n",
    "\n",
    "                data.append((jpg_file, ply_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782426d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_png_file(file_path):\n",
    "    \"\"\"\n",
    "    Загрузка PNG-файла и препроцессинг\n",
    "\n",
    "    Аргументы:\n",
    "    file_path (str): Путь к PNG-файлу\n",
    "\n",
    "    Возвращает:\n",
    "    square_data (np.array): Массив с данными из PNG-файла\n",
    "    \"\"\"\n",
    "    # Загружаем PNG-файл с использованием OpenCV\n",
    "    png_data = cv2.imread(file_path)\n",
    "\n",
    "    # Преобразуем изображение в оттенки серого\n",
    "    grayscale_data = cv2.cvtColor(png_data, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Используем пороговое значение (thresholding) для создания бинарного изображения\n",
    "    _, binary_data = cv2.threshold(grayscale_data, 250, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Находим контуры объектов на бинарном изображении\n",
    "    contours, _ = cv2.findContours(binary_data, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Вычисляем границы области интереса\n",
    "    x_min, y_min, x_max, y_max = np.inf, np.inf, 0, 0\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        x_min = min(x_min, x)\n",
    "        y_min = min(y_min, y)\n",
    "        x_max = max(x_max, x + w)\n",
    "        y_max = max(y_max, y + h)\n",
    "\n",
    "    # Вычисляем размеры области интереса и определяем размер квадрата\n",
    "    width, height = x_max - x_min, y_max - y_min\n",
    "    square_size = max(width, height)\n",
    "\n",
    "    # Вычисляем координаты верхнего левого угла квадрата\n",
    "    x_start = max(0, x_min + (width - square_size) // 2)\n",
    "    y_start = max(0, y_min + (height - square_size) // 2)\n",
    "\n",
    "    # Вырезаем квадратное изображение\n",
    "    square_data = grayscale_data[y_start:y_start + square_size, x_start:x_start + square_size]\n",
    "\n",
    "    # Изменяем размер квадратного изображения на 127x127\n",
    "    square_data = cv2.resize(square_data, (127, 127))\n",
    "\n",
    "    # Нормализуем значения пикселей\n",
    "    square_data = square_data.astype(np.float32) / 255.0\n",
    "    square_data = np.expand_dims(square_data, axis=2)\n",
    "\n",
    "    return square_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_ply_file(file_path, resolution=32):\n",
    "    pcd = o3d.io.read_point_cloud(file_path)\n",
    "    xyz_load = np.asarray(pcd.points)\n",
    "\n",
    "    # Вычисление минимальных и максимальных координат\n",
    "    min_coords = np.min(xyz_load, axis=0)\n",
    "    max_coords = np.max(xyz_load, axis=0)\n",
    "\n",
    "    # Вычислить текущий диапазон значений по каждой оси\n",
    "    ranges = max_coords - min_coords\n",
    "\n",
    "    # Найти максимальный диапазон среди всех осей\n",
    "    max_range = np.max(ranges)\n",
    "\n",
    "    # Вычислить масштабный коэффициент для каждой оси\n",
    "    scale_factor = (resolution - 1) / max_range\n",
    "\n",
    "    # Вычитать минимальные значения каждой оси из всех точек и умножить их на масштабный коэффициент\n",
    "    scaled_points = (xyz_load - min_coords) * scale_factor\n",
    "    scaled_points = np.round(scaled_points).astype(int)\n",
    "\n",
    "    # Создание пустого массива размерности (32, 32, 32)\n",
    "    voxel_array = np.zeros((resolution, resolution, resolution, 1), dtype=np.uint8)\n",
    "\n",
    "    # Заполнение массива на основе координат точек\n",
    "    for point in scaled_points:\n",
    "        x, y, z = point\n",
    "        voxel_array[x, y, z] = 1\n",
    "\n",
    "    return voxel_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    x = []\n",
    "    y = []\n",
    "        \n",
    "    for jpeg_path, ply_path in data:\n",
    "        jpeg_data = load_png_file(jpeg_path)\n",
    "        ply_data = load_ply_file(ply_path)\n",
    "        x.append(jpeg_data)\n",
    "        y.append(ply_data)\n",
    "    return np.asarray(x), np.asarray(y)\n",
    "\n",
    "def prepare_data(data, test_size=0.1, random_state=123):\n",
    "    x, y = preprocess_data(data)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
    "    return x_train, x_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f89c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = prepare_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "\n",
    "class Conv2DWithBatchNormalizationWithRelu(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides=(1, 1), use_batch_norm=False, name=None, kernel_initializer='glorot_uniform', kernel_regularizer=None, **kwargs):\n",
    "        super(Conv2DWithBatchNormalizationWithRelu, self).__init__(name=name, **kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv2d_weights = self.add_weight(name=f\"{self.name}_conv2d_weights\",\n",
    "                                              shape=(self.kernel_size[0], self.kernel_size[1], input_shape[-1], self.filters),\n",
    "                                              initializer=self.kernel_initializer,\n",
    "                                              regularizer=self.kernel_regularizer,\n",
    "                                              trainable=True)\n",
    "        if self.use_batch_norm:\n",
    "            self.batch_mean = tf.Variable(tf.zeros(self.filters), name=f\"{self.name}_batch_mean\")\n",
    "            self.batch_var = tf.Variable(tf.ones(self.filters), name=f\"{self.name}_batch_var\")\n",
    "            self.beta = tf.Variable(tf.zeros(self.filters), name=f\"{self.name}_beta\")\n",
    "            self.gamma = tf.Variable(tf.ones(self.filters), name=f\"{self.name}_gamma\")\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = tf.nn.conv2d(inputs, self.conv2d_weights, strides=[1, *self.strides, 1], padding='SAME', name=f\"{self.name}_conv2d\")\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            mean, variance = tf.nn.moments(x, axes=[0, 1, 2], keepdims=False)\n",
    "\n",
    "            if training:\n",
    "                x_normalized = (x - mean) / tf.math.sqrt(variance + 1e-5)\n",
    "            else:\n",
    "                x_normalized = (x - self.batch_mean) / tf.math.sqrt(self.batch_var + 1e-5)\n",
    "\n",
    "            x = self.gamma * x_normalized + self.beta\n",
    "        \n",
    "        y = tf.nn.leaky_relu(x, alpha=0.1, name=f\"{self.name}_leaky_relu\")\n",
    "        return y\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"strides\": self.strides,\n",
    "            \"use_batch_norm\": self.use_batch_norm,\n",
    "            \"kernel_initializer\": self.kernel_initializer,\n",
    "            \"kernel_regularizer\": self.kernel_regularizer\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e476bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import L1L2\n",
    "from keras import initializers\n",
    "\n",
    "l1_coeff = 0.000\n",
    "l2_coeff = 0.000\n",
    "\n",
    "batch_size = 32\n",
    "initializer = initializers.HeNormal(seed=123)\n",
    "regularizer = tf.keras.regularizers.l1_l2(l1=l1_coeff, l2=l2_coeff)\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=[127, 127, 1], batch_size=batch_size, name='input_layer')\n",
    "\n",
    "###\n",
    "conv0_0 = Conv2DWithBatchNormalizationWithRelu(filters=64, kernel_size=(7, 7), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv0_0')(inputs)\n",
    "conv0_1 = Conv2DWithBatchNormalizationWithRelu(filters=64, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv0_1')(conv0_0)\n",
    "shortcut0 = Conv2DWithBatchNormalizationWithRelu(filters=64, kernel_size=(1, 1), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='shortcut0')(inputs)\n",
    "output0 = tf.nn.max_pool(conv0_1 + shortcut0, ksize=(2, 2), strides=(2, 2), padding='SAME', name='output0')\n",
    "\n",
    "conv1_0 = Conv2DWithBatchNormalizationWithRelu(filters=64, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv1_0')(output0)\n",
    "conv1_1 = Conv2DWithBatchNormalizationWithRelu(filters=64, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv1_1')(conv1_0)\n",
    "shortcut1 = Conv2DWithBatchNormalizationWithRelu(filters=64, kernel_size=(1, 1), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='shortcut1')(output0)\n",
    "output1 = tf.nn.max_pool(conv1_1 + shortcut1, ksize=(2, 2), strides=(2, 2), padding='SAME', name='output1')\n",
    "\n",
    "conv2_0 = Conv2DWithBatchNormalizationWithRelu(filters=128, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv2_0')(output1)\n",
    "conv2_1 = Conv2DWithBatchNormalizationWithRelu(filters=128, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv2_1')(conv2_0)\n",
    "shortcut2 = Conv2DWithBatchNormalizationWithRelu(filters=128, kernel_size=(1, 1), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='shortcut2')(output1)\n",
    "output2 = tf.nn.max_pool(conv2_1 + shortcut2, ksize=(2, 2), strides=(2, 2), padding='SAME', name='output2')\n",
    "\n",
    "conv3_0 = Conv2DWithBatchNormalizationWithRelu(filters=128, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv3_0')(output2)\n",
    "conv3_1 = Conv2DWithBatchNormalizationWithRelu(filters=128, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv3_1')(conv3_0)\n",
    "output3 = tf.nn.max_pool(conv3_1, ksize=(2, 2), strides=(2, 2), padding='SAME', name='output3')\n",
    "\n",
    "conv4_0 = Conv2DWithBatchNormalizationWithRelu(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv4_0')(output3)\n",
    "conv4_1 = Conv2DWithBatchNormalizationWithRelu(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv4_1')(conv4_0)\n",
    "shortcut4 = Conv2DWithBatchNormalizationWithRelu(filters=256, kernel_size=(1, 1), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='shortcut4')(output3)\n",
    "output4 = tf.nn.max_pool(conv4_1 + shortcut4, ksize=(2, 2), strides=(2, 2), padding='SAME', name='output4')\n",
    "\n",
    "conv5_0 = Conv2DWithBatchNormalizationWithRelu(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv5_0')(output4)\n",
    "conv5_1 = Conv2DWithBatchNormalizationWithRelu(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv5_1')(conv5_0)\n",
    "shortcut5 = Conv2DWithBatchNormalizationWithRelu(filters=256, kernel_size=(1, 1), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='shortcut5')(output4)\n",
    "output5 = tf.nn.max_pool(conv5_1 + shortcut5, ksize=(2, 2), strides=(1, 1), padding='SAME', name='output5')\n",
    "\n",
    "decoder_input = layers.Reshape((2, 2, 2, 512), name='reshape_decoder_input')(output5)\n",
    "\n",
    "unpool0 = tf.keras.layers.UpSampling3D(size=(2, 2, 2), name='unpool0')(decoder_input)\n",
    "deshortcut0 = tf.keras.layers.Conv3D(filters=256, kernel_size=1, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deshortcut0')(unpool0)\n",
    "deconv0_0 = tf.keras.layers.Conv3D(filters=256, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv0_0')(deshortcut0)\n",
    "deconv0_1 = tf.keras.layers.Conv3D(filters=256, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv0_1')(deconv0_0)\n",
    "output0 = tf.add(deshortcut0, deconv0_1, name='dec_output0')\n",
    "\n",
    "\n",
    "unpool1 = tf.keras.layers.UpSampling3D(size=(2, 2, 2), name='unpool1')(output0)\n",
    "deshortcut1 = tf.keras.layers.Conv3D(filters=128, kernel_size=1, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deshortcut1')(unpool1)\n",
    "deconv1_0 = tf.keras.layers.Conv3D(filters=128, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv1_0')(deshortcut1)\n",
    "deconv1_1 = tf.keras.layers.Conv3D(filters=128, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv1_1')(deconv1_0)\n",
    "output1 = tf.add(deshortcut1, deconv1_1, name='dec_output1')\n",
    "\n",
    "unpool2 = tf.keras.layers.UpSampling3D(size=(2, 2, 2), name='unpool2')(output1)\n",
    "deshortcut2 = tf.keras.layers.Conv3D(filters=64, kernel_size=1, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deshortcut2')(unpool2)\n",
    "deconv2_0 = tf.keras.layers.Conv3D(filters=64, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv2_0')(unpool2)\n",
    "deconv2_1 = tf.keras.layers.Conv3D(filters=64, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv2_1')(deconv2_0)\n",
    "output2 = tf.add(deshortcut2, deconv2_1, name='dec_output2')\n",
    "\n",
    "unpool3 = tf.keras.layers.UpSampling3D(size=(2, 2, 2), name='unpool3')(output2)\n",
    "deshortcut3 = tf.keras.layers.Conv3D(filters=32, kernel_size=1, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deshortcut3')(unpool3)\n",
    "deconv3_0 = tf.keras.layers.Conv3D(filters=32, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv3_0')(deshortcut3)\n",
    "deconv3_1 = tf.keras.layers.Conv3D(filters=32, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv3_1')(deconv3_0)\n",
    "deconv3_2 = tf.keras.layers.Conv3D(filters=32, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv3_2')(deconv3_1)\n",
    "output3 = tf.add(deshortcut3, deconv3_2, name='dec_output3')\n",
    "\n",
    "deshortcut4 = tf.keras.layers.Conv3D(filters=16, kernel_size=1, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deshortcut4')(output3)\n",
    "deconv4_0 = tf.keras.layers.Conv3D(filters=16, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv4_0')(deshortcut4)\n",
    "deconv4_1 = tf.keras.layers.Conv3D(filters=16, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv4_1')(deconv4_0)\n",
    "output4 = tf.add(deshortcut4, deconv4_1, name='dec_output4')\n",
    "\n",
    "output = tf.keras.layers.Conv3D(filters=1, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='sigmoid', name='dec_output4')(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "\n",
    "def batch_iou(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(K.clip(y_pred, 0, 1), 'float32')\n",
    "    \n",
    "    y_true_f = K.batch_flatten(y_true)\n",
    "    y_pred_f = K.batch_flatten(y_pred)\n",
    "    \n",
    "    intersection = K.sum(y_true_f * y_pred_f, axis=-1)\n",
    "    union = K.sum(y_true_f, axis=-1) + K.sum(y_pred_f, axis=-1) - intersection\n",
    "    \n",
    "    jac = (intersection + 0.00001) / (union + 0.00001)\n",
    "    \n",
    "    return K.mean(jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import Loss\n",
    "import os\n",
    "import logging\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(\n",
    "    learning_rate=0.0005704251931830293,\n",
    "    beta_1=0.969977395782997,\n",
    "    beta_2=0.9924554943638575,\n",
    "    epsilon=2.463546078002056e-09\n",
    ")\n",
    "\n",
    "\n",
    "        \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'  # 0 = default (all messages), 1 = info and warnings, 2 = warnings and errors, 3 = errors only\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperModel\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from keras import initializers\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "# Класс для подбора гиперпараметров по сетке\n",
    "\n",
    "class CustomHyperModel(HyperModel):\n",
    "    def __init__(self):\n",
    "        self.all_histories = [] \n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        filename = \"training_metrics_FINAL.txt\"\n",
    "        mode = \"w\" if not os.path.exists(filename) else \"a\"\n",
    "        \n",
    "        history = model.fit(*args, **kwargs)\n",
    "        self.all_histories.append(history)  \n",
    "        val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "        with open(filename, mode) as f:\n",
    "            f.write(f\"Epoch {len(self.all_histories)}:\\n\")\n",
    "            for key, value in history.history.items():\n",
    "                f.write(f\"{key}: {value[-1]}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        return val_loss\n",
    "\n",
    "    def build(self, hp):\n",
    "    \n",
    "        loss = tf.keras.losses.BinaryCrossentropy()\n",
    "                        \n",
    "        l1_coeff = 0\n",
    "        l2_coeff = 0\n",
    "\n",
    "        \n",
    "        initializer_choice = hp.Choice('initializer', ['he_normal', 'lecun_normal', 'glorot_normal'])\n",
    "\n",
    "        if initializer_choice == 'he_normal':\n",
    "            initializer = initializers.HeNormal(seed=123)\n",
    "        elif initializer_choice == 'lecun_normal':\n",
    "            initializer = initializers.LecunNormal(seed=123)\n",
    "        else:\n",
    "            initializer = initializers.GlorotNormal(seed=123)\n",
    "            \n",
    "\n",
    "        batch_size = 32\n",
    "        regularizer = tf.keras.regularizers.l1_l2(l1=l1_coeff, l2=l2_coeff)\n",
    "\n",
    "\n",
    "        inputs = tf.keras.Input(shape=[127, 127, 1], batch_size=batch_size, name='input_layer')\n",
    "\n",
    "        ###\n",
    "        conv0_0 = Conv2DWithBatchNormalizationWithRelu(filters=64, kernel_size=(7, 7), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv0_0')(inputs)\n",
    "        conv0_1 = Conv2DWithBatchNormalizationWithRelu(filters=64, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv0_1')(conv0_0)\n",
    "        shortcut0 = Conv2DWithBatchNormalizationWithRelu(filters=64, kernel_size=(1, 1), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='shortcut0')(inputs)\n",
    "        output0 = tf.nn.max_pool(conv0_1 + shortcut0, ksize=(2, 2), strides=(2, 2), padding='SAME', name='output0')\n",
    "\n",
    "        conv1_0 = Conv2DWithBatchNormalizationWithRelu(filters=64, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv1_0')(output0)\n",
    "        conv1_1 = Conv2DWithBatchNormalizationWithRelu(filters=64, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv1_1')(conv1_0)\n",
    "        shortcut1 = Conv2DWithBatchNormalizationWithRelu(filters=64, kernel_size=(1, 1), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='shortcut1')(output0)\n",
    "        output1 = tf.nn.max_pool(conv1_1 + shortcut1, ksize=(2, 2), strides=(2, 2), padding='SAME', name='output1')\n",
    "\n",
    "        conv2_0 = Conv2DWithBatchNormalizationWithRelu(filters=128, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv2_0')(output1)\n",
    "        conv2_1 = Conv2DWithBatchNormalizationWithRelu(filters=128, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv2_1')(conv2_0)\n",
    "        shortcut2 = Conv2DWithBatchNormalizationWithRelu(filters=128, kernel_size=(1, 1), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='shortcut2')(output1)\n",
    "        output2 = tf.nn.max_pool(conv2_1 + shortcut2, ksize=(2, 2), strides=(2, 2), padding='SAME', name='output2')\n",
    "\n",
    "        conv3_0 = Conv2DWithBatchNormalizationWithRelu(filters=128, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv3_0')(output2)\n",
    "        conv3_1 = Conv2DWithBatchNormalizationWithRelu(filters=128, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv3_1')(conv3_0)\n",
    "        output3 = tf.nn.max_pool(conv3_1, ksize=(2, 2), strides=(2, 2), padding='SAME', name='output3')\n",
    "\n",
    "        conv4_0 = Conv2DWithBatchNormalizationWithRelu(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv4_0')(output3)\n",
    "        conv4_1 = Conv2DWithBatchNormalizationWithRelu(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv4_1')(conv4_0)\n",
    "        shortcut4 = Conv2DWithBatchNormalizationWithRelu(filters=256, kernel_size=(1, 1), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='shortcut4')(output3)\n",
    "        output4 = tf.nn.max_pool(conv4_1 + shortcut4, ksize=(2, 2), strides=(2, 2), padding='SAME', name='output4')\n",
    "\n",
    "        conv5_0 = Conv2DWithBatchNormalizationWithRelu(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv5_0')(output4)\n",
    "        conv5_1 = Conv2DWithBatchNormalizationWithRelu(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='conv5_1')(conv5_0)\n",
    "        shortcut5 = Conv2DWithBatchNormalizationWithRelu(filters=256, kernel_size=(1, 1), strides=(1, 1), kernel_initializer=initializer, kernel_regularizer=regularizer, name='shortcut5')(output4)\n",
    "        output5 = tf.nn.max_pool(conv5_1 + shortcut5, ksize=(2, 2), strides=(1, 1), padding='SAME', name='output5')\n",
    "        \n",
    "        decoder_input = layers.Reshape((2, 2, 2, 512), name='reshape_decoder_input')(output5)\n",
    "\n",
    "        unpool0 = tf.keras.layers.UpSampling3D(size=(2, 2, 2), name='unpool0')(decoder_input)\n",
    "        deshortcut0 = tf.keras.layers.Conv3D(filters=256, kernel_size=1, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deshortcut0')(unpool0)\n",
    "        deconv0_0 = tf.keras.layers.Conv3D(filters=256, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv0_0')(deshortcut0)\n",
    "        deconv0_1 = tf.keras.layers.Conv3D(filters=256, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv0_1')(deconv0_0)\n",
    "        output0 = tf.add(deshortcut0, deconv0_1, name='dec_output0')\n",
    "\n",
    "\n",
    "        unpool1 = tf.keras.layers.UpSampling3D(size=(2, 2, 2), name='unpool1')(output0)\n",
    "        deshortcut1 = tf.keras.layers.Conv3D(filters=128, kernel_size=1, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deshortcut1')(unpool1)\n",
    "        deconv1_0 = tf.keras.layers.Conv3D(filters=128, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv1_0')(deshortcut1)\n",
    "        deconv1_1 = tf.keras.layers.Conv3D(filters=128, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv1_1')(deconv1_0)\n",
    "        output1 = tf.add(deshortcut1, deconv1_1, name='dec_output1')\n",
    "\n",
    "        unpool2 = tf.keras.layers.UpSampling3D(size=(2, 2, 2), name='unpool2')(output1)\n",
    "        deshortcut2 = tf.keras.layers.Conv3D(filters=64, kernel_size=1, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deshortcut2')(unpool2)\n",
    "        deconv2_0 = tf.keras.layers.Conv3D(filters=64, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv2_0')(unpool2)\n",
    "        deconv2_1 = tf.keras.layers.Conv3D(filters=64, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv2_1')(deconv2_0)\n",
    "        output2 = tf.add(deshortcut2, deconv2_1, name='dec_output2')\n",
    "\n",
    "        unpool3 = tf.keras.layers.UpSampling3D(size=(2, 2, 2), name='unpool3')(output2)\n",
    "        deshortcut3 = tf.keras.layers.Conv3D(filters=32, kernel_size=1, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deshortcut3')(unpool3)\n",
    "        deconv3_0 = tf.keras.layers.Conv3D(filters=32, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv3_0')(deshortcut3)\n",
    "        deconv3_1 = tf.keras.layers.Conv3D(filters=32, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv3_1')(deconv3_0)\n",
    "        deconv3_2 = tf.keras.layers.Conv3D(filters=32, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv3_2')(deconv3_1)\n",
    "        output3 = tf.add(deshortcut3, deconv3_2, name='dec_output3')\n",
    "\n",
    "        deshortcut4 = tf.keras.layers.Conv3D(filters=16, kernel_size=1, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deshortcut4')(output3)\n",
    "        deconv4_0 = tf.keras.layers.Conv3D(filters=16, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv4_0')(deshortcut4)\n",
    "        deconv4_1 = tf.keras.layers.Conv3D(filters=16, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='relu', name='deconv4_1')(deconv4_0)\n",
    "        output4 = tf.add(deshortcut4, deconv4_1, name='dec_output4')\n",
    "\n",
    "        output = tf.keras.layers.Conv3D(filters=1, kernel_size=3, strides=(1, 1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=L1L2(l1=l1_coeff, l2=l2_coeff), activation='sigmoid', name='dec_output4')(output4)\n",
    "\n",
    "        \n",
    "        model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "        loss = tf.keras.losses.BinaryCrossentropy()\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(\n",
    "                learning_rate=hp.Float('learning_rate', 1e-5, 1e-3, sampling='LOG'),\n",
    "                beta_1=hp.Float('beta_1', 0.90, 1, sampling='LOG'),\n",
    "                beta_2=hp.Float('beta_2', 0.99, 1, sampling='LOG'),\n",
    "                epsilon=hp.Float('epsilon', 1e-9, 1e-6, sampling='LOG')\n",
    "            ),\n",
    "            loss = loss,\n",
    "            metrics=[BinaryAccuracy(), batch_iou]\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbd18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = CustomHyperModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1145824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.tuners import GridSearch, RandomSearch\n",
    "from keras_tuner import Objective\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective=Objective('val_loss', direction='min'),\n",
    "    max_trials=10,  # количество комбинаций для проверки\n",
    "    directory='FINAL_DIR',\n",
    "    project_name='my_project',\n",
    "    overwrite=False,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "test_size = len(x_test) // batch_size * batch_size\n",
    "train_size = len(x_train) // batch_size * batch_size\n",
    "tuner.search(x_train[:train_size], y_train[:train_size], epochs=10, validation_data=(x_test[:test_size], y_test[:test_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa187f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def batch_generator(x, y, batch_size):\n",
    "    num_samples = x.shape[0]\n",
    "    while True:\n",
    "        # Перемешиваем индексы перед каждой эпохой\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        for start_idx in range(0, num_samples, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, num_samples)\n",
    "            batch_indices = indices[start_idx:end_idx]\n",
    "            x_batch = x[batch_indices]\n",
    "            y_batch = y[batch_indices]\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = batch_generator(x_train, y_train, batch_size)\n",
    "validation_gen = batch_generator(x_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be36e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ecb992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(filepath='model_{epoch:02d}_FINAL_01viewWDS.h5', period=5, save_best_only=True, save_weights_only=False, verbose=1)\n",
    "\n",
    "    \n",
    "history = best_model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(x_train) // batch_size,\n",
    "    epochs=200,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=len(x_test) // batch_size,\n",
    "    callbacks=[early_stopping, reduce_lr, model_check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
